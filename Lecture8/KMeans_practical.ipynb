{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mode\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load and process dataset\n",
    "load breast_cancer.csv, drop columns \"id\" and \"Unnamed: 32\", investigate the dataset, and divide into train and test with 80/20 ratio, map values of \"diagnosis\" from (\"B\",\"M\") to (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = pd.read_csv('breast_cancer.csv')\n",
    "X = original_data.drop(['id', 'Unnamed: 32'], axis=1)\n",
    "target_col = 'diagnosis'\n",
    "X.loc[X[target_col] == 'M', 'diagnosis'] = 1\n",
    "X.loc[X[target_col] == 'B', 'diagnosis'] = 0\n",
    "X[target_col] = X[target_col].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "setting number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "K = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We have two very strong outliers, which in future will make serious influence on algorithm and sometimes stick one cluster center and dont let to it to be changed\n",
    "These are rows 212 and 461\n",
    "We should delete them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X.drop(212, axis=0, inplace=True)\n",
    "X.drop(461, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRELATION MATRIX:\n",
      "Correlation between area_mean and target column:  0.7230194885685689\n",
      "Correlation between area_se and target column:  0.6543415456204112\n",
      "Correlation between area_worst and target column:  0.7448380011989271\n",
      "Correlation between compactness_mean and target column:  0.5942507555534166\n",
      "Correlation between compactness_se and target column:  0.290603028749923\n",
      "Correlation between compactness_worst and target column:  0.5926000675832344\n",
      "Correlation between concave points_mean and target column:  0.7775205070637204\n",
      "Correlation between concave points_se and target column:  0.40507334289059854\n",
      "Correlation between concave points_worst and target column:  0.7930748115655999\n",
      "Correlation between concavity_mean and target column:  0.6964521916907342\n",
      "Correlation between concavity_se and target column:  0.24916850970137372\n",
      "Correlation between concavity_worst and target column:  0.658814461765053\n",
      "Correlation between fractal_dimension_mean and target column:  -0.008297389429912686\n",
      "Correlation between fractal_dimension_se and target column:  0.07696123170322855\n",
      "Correlation between fractal_dimension_worst and target column:  0.33054085204079475\n",
      "Correlation between perimeter_mean and target column:  0.7475378929188699\n",
      "Correlation between perimeter_se and target column:  0.6046080031259043\n",
      "Correlation between perimeter_worst and target column:  0.7868499671822378\n",
      "Correlation between radius_mean and target column:  0.7341253048775574\n",
      "Correlation between radius_se and target column:  0.6108159124628159\n",
      "Correlation between radius_worst and target column:  0.7795567596032265\n",
      "Correlation between smoothness_mean and target column:  0.35548460027559114\n",
      "Correlation between smoothness_se and target column:  -0.07288229726244651\n",
      "Correlation between smoothness_worst and target column:  0.42446008346109265\n",
      "Correlation between symmetry_mean and target column:  0.33111101113756514\n",
      "Correlation between symmetry_se and target column:  -0.013262771755251488\n",
      "Correlation between symmetry_worst and target column:  0.4247590967411725\n",
      "Correlation between texture_mean and target column:  0.4141088606312366\n",
      "Correlation between texture_se and target column:  -0.009780813871471393\n",
      "Correlation between texture_worst and target column:  0.4597365770466981\n"
     ]
    }
   ],
   "source": [
    "print('CORRELATION MATRIX:')\n",
    "for feature in X.columns.difference([target_col]):\n",
    "    print(f'Correlation between {feature} and target column: ', X[[feature, target_col]].corr().iloc[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X[target_col]\n",
    "X.drop(target_col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of malignant diagnosis:  357\n",
      "Number of benign diagnosis:  210\n"
     ]
    }
   ],
   "source": [
    "print('Number of malignant diagnosis: ', y.value_counts().loc[0])\n",
    "print('Number of benign diagnosis: ', y.value_counts().loc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>radius_se</th>\n",
       "      <th>texture_se</th>\n",
       "      <th>perimeter_se</th>\n",
       "      <th>area_se</th>\n",
       "      <th>smoothness_se</th>\n",
       "      <th>compactness_se</th>\n",
       "      <th>concavity_se</th>\n",
       "      <th>concave points_se</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>567.000000</td>\n",
       "      <td>567.000000</td>\n",
       "      <td>567.000000</td>\n",
       "      <td>567.000000</td>\n",
       "      <td>567.000000</td>\n",
       "      <td>567.000000</td>\n",
       "      <td>567.000000</td>\n",
       "      <td>567.000000</td>\n",
       "      <td>567.000000</td>\n",
       "      <td>567.000000</td>\n",
       "      <td>567.000000</td>\n",
       "      <td>567.000000</td>\n",
       "      <td>567.000000</td>\n",
       "      <td>567.000000</td>\n",
       "      <td>567.000000</td>\n",
       "      <td>567.000000</td>\n",
       "      <td>567.000000</td>\n",
       "      <td>567.000000</td>\n",
       "      <td>567.000000</td>\n",
       "      <td>567.000000</td>\n",
       "      <td>567.000000</td>\n",
       "      <td>567.000000</td>\n",
       "      <td>567.000000</td>\n",
       "      <td>567.000000</td>\n",
       "      <td>567.000000</td>\n",
       "      <td>567.000000</td>\n",
       "      <td>567.000000</td>\n",
       "      <td>567.000000</td>\n",
       "      <td>567.000000</td>\n",
       "      <td>567.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.079187</td>\n",
       "      <td>19.278783</td>\n",
       "      <td>91.631358</td>\n",
       "      <td>648.380776</td>\n",
       "      <td>0.096308</td>\n",
       "      <td>0.104091</td>\n",
       "      <td>0.087907</td>\n",
       "      <td>0.048513</td>\n",
       "      <td>0.181147</td>\n",
       "      <td>0.062823</td>\n",
       "      <td>0.397042</td>\n",
       "      <td>1.216239</td>\n",
       "      <td>2.804511</td>\n",
       "      <td>38.596116</td>\n",
       "      <td>0.007029</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.031751</td>\n",
       "      <td>0.011767</td>\n",
       "      <td>0.020500</td>\n",
       "      <td>0.003792</td>\n",
       "      <td>16.213437</td>\n",
       "      <td>25.679894</td>\n",
       "      <td>106.864074</td>\n",
       "      <td>871.779189</td>\n",
       "      <td>0.132395</td>\n",
       "      <td>0.254144</td>\n",
       "      <td>0.271379</td>\n",
       "      <td>0.114266</td>\n",
       "      <td>0.290342</td>\n",
       "      <td>0.084013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.435530</td>\n",
       "      <td>4.298475</td>\n",
       "      <td>23.664895</td>\n",
       "      <td>334.976006</td>\n",
       "      <td>0.014060</td>\n",
       "      <td>0.052719</td>\n",
       "      <td>0.078416</td>\n",
       "      <td>0.038259</td>\n",
       "      <td>0.027434</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.241336</td>\n",
       "      <td>0.552502</td>\n",
       "      <td>1.735771</td>\n",
       "      <td>34.823434</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>0.030140</td>\n",
       "      <td>0.006152</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>0.002650</td>\n",
       "      <td>4.743557</td>\n",
       "      <td>6.144992</td>\n",
       "      <td>32.934746</td>\n",
       "      <td>548.180273</td>\n",
       "      <td>0.022860</td>\n",
       "      <td>0.157390</td>\n",
       "      <td>0.208266</td>\n",
       "      <td>0.065526</td>\n",
       "      <td>0.061742</td>\n",
       "      <td>0.018048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>0.111500</td>\n",
       "      <td>0.360200</td>\n",
       "      <td>0.757000</td>\n",
       "      <td>6.802000</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007882</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.695000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.100000</td>\n",
       "      <td>420.050000</td>\n",
       "      <td>0.086210</td>\n",
       "      <td>0.064710</td>\n",
       "      <td>0.029520</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057800</td>\n",
       "      <td>0.232350</td>\n",
       "      <td>0.832400</td>\n",
       "      <td>1.604000</td>\n",
       "      <td>17.850000</td>\n",
       "      <td>0.005163</td>\n",
       "      <td>0.013015</td>\n",
       "      <td>0.015035</td>\n",
       "      <td>0.007631</td>\n",
       "      <td>0.015095</td>\n",
       "      <td>0.002241</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.090000</td>\n",
       "      <td>84.095000</td>\n",
       "      <td>514.650000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.146600</td>\n",
       "      <td>0.114450</td>\n",
       "      <td>0.064530</td>\n",
       "      <td>0.250450</td>\n",
       "      <td>0.071465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.340000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.180000</td>\n",
       "      <td>546.400000</td>\n",
       "      <td>0.095860</td>\n",
       "      <td>0.092420</td>\n",
       "      <td>0.061260</td>\n",
       "      <td>0.033410</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061550</td>\n",
       "      <td>0.323700</td>\n",
       "      <td>1.108000</td>\n",
       "      <td>2.284000</td>\n",
       "      <td>24.440000</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.020420</td>\n",
       "      <td>0.025860</td>\n",
       "      <td>0.010910</td>\n",
       "      <td>0.018730</td>\n",
       "      <td>0.003136</td>\n",
       "      <td>14.960000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.650000</td>\n",
       "      <td>684.600000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226400</td>\n",
       "      <td>0.099750</td>\n",
       "      <td>0.282300</td>\n",
       "      <td>0.080060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.765000</td>\n",
       "      <td>21.790000</td>\n",
       "      <td>103.750000</td>\n",
       "      <td>781.800000</td>\n",
       "      <td>0.105200</td>\n",
       "      <td>0.130350</td>\n",
       "      <td>0.128250</td>\n",
       "      <td>0.073520</td>\n",
       "      <td>0.195650</td>\n",
       "      <td>0.066135</td>\n",
       "      <td>0.475950</td>\n",
       "      <td>1.473500</td>\n",
       "      <td>3.321000</td>\n",
       "      <td>44.935000</td>\n",
       "      <td>0.008135</td>\n",
       "      <td>0.032295</td>\n",
       "      <td>0.041615</td>\n",
       "      <td>0.014710</td>\n",
       "      <td>0.023425</td>\n",
       "      <td>0.004537</td>\n",
       "      <td>18.655000</td>\n",
       "      <td>29.690000</td>\n",
       "      <td>125.050000</td>\n",
       "      <td>1060.000000</td>\n",
       "      <td>0.146050</td>\n",
       "      <td>0.338100</td>\n",
       "      <td>0.381900</td>\n",
       "      <td>0.161350</td>\n",
       "      <td>0.318150</td>\n",
       "      <td>0.092085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>27.220000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>182.100000</td>\n",
       "      <td>2250.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>1.509000</td>\n",
       "      <td>4.885000</td>\n",
       "      <td>11.070000</td>\n",
       "      <td>233.000000</td>\n",
       "      <td>0.031130</td>\n",
       "      <td>0.135400</td>\n",
       "      <td>0.396000</td>\n",
       "      <td>0.052790</td>\n",
       "      <td>0.078950</td>\n",
       "      <td>0.029840</td>\n",
       "      <td>33.130000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>229.300000</td>\n",
       "      <td>3432.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       radius_mean  texture_mean  perimeter_mean    area_mean  smoothness_mean  compactness_mean  concavity_mean  concave points_mean  symmetry_mean  fractal_dimension_mean   radius_se  texture_se  perimeter_se     area_se  smoothness_se  compactness_se  concavity_se  concave points_se  symmetry_se  fractal_dimension_se  radius_worst  texture_worst  perimeter_worst   area_worst  smoothness_worst  compactness_worst  concavity_worst  concave points_worst  symmetry_worst  fractal_dimension_worst\n",
       "count   567.000000    567.000000      567.000000   567.000000       567.000000        567.000000      567.000000           567.000000     567.000000              567.000000  567.000000  567.000000    567.000000  567.000000     567.000000      567.000000    567.000000         567.000000   567.000000            567.000000    567.000000     567.000000       567.000000   567.000000        567.000000         567.000000       567.000000            567.000000      567.000000               567.000000\n",
       "mean     14.079187     19.278783       91.631358   648.380776         0.096308          0.104091        0.087907             0.048513       0.181147                0.062823    0.397042    1.216239      2.804511   38.596116       0.007029        0.025424      0.031751           0.011767     0.020500              0.003792     16.213437      25.679894       106.864074   871.779189          0.132395           0.254144         0.271379              0.114266        0.290342                 0.084013\n",
       "std       3.435530      4.298475       23.664895   334.976006         0.014060          0.052719        0.078416             0.038259       0.027434                0.007060    0.241336    0.552502      1.735771   34.823434       0.002996        0.017900      0.030140           0.006152     0.008200              0.002650      4.743557       6.144992        32.934746   548.180273          0.022860           0.157390         0.208266              0.065526        0.061742                 0.018048\n",
       "min       6.981000      9.710000       43.790000   143.500000         0.052630          0.019380        0.000000             0.000000       0.106000                0.049960    0.111500    0.360200      0.757000    6.802000       0.001713        0.002252      0.000000           0.000000     0.007882              0.000895      7.930000      12.020000        50.410000   185.200000          0.071170           0.027290         0.000000              0.000000        0.156500                 0.055040\n",
       "25%      11.695000     16.170000       75.100000   420.050000         0.086210          0.064710        0.029520             0.020310       0.161900                0.057800    0.232350    0.832400      1.604000   17.850000       0.005163        0.013015      0.015035           0.007631     0.015095              0.002241     13.010000      21.090000        84.095000   514.650000          0.116600           0.146600         0.114450              0.064530        0.250450                 0.071465\n",
       "50%      13.340000     18.840000       86.180000   546.400000         0.095860          0.092420        0.061260             0.033410       0.179200                0.061550    0.323700    1.108000      2.284000   24.440000       0.006369        0.020420      0.025860           0.010910     0.018730              0.003136     14.960000      25.410000        97.650000   684.600000          0.131300           0.211900         0.226400              0.099750        0.282300                 0.080060\n",
       "75%      15.765000     21.790000      103.750000   781.800000         0.105200          0.130350        0.128250             0.073520       0.195650                0.066135    0.475950    1.473500      3.321000   44.935000       0.008135        0.032295      0.041615           0.014710     0.023425              0.004537     18.655000      29.690000       125.050000  1060.000000          0.146050           0.338100         0.381900              0.161350        0.318150                 0.092085\n",
       "max      27.220000     39.280000      182.100000  2250.000000         0.163400          0.345400        0.426800             0.201200       0.304000                0.097440    1.509000    4.885000     11.070000  233.000000       0.031130        0.135400      0.396000           0.052790     0.078950              0.029840     33.130000      49.540000       229.300000  3432.000000          0.222600           1.058000         1.252000              0.291000        0.663800                 0.207500"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "radius_mean                 14.079187\n",
       "texture_mean                19.278783\n",
       "perimeter_mean              91.631358\n",
       "area_mean                  648.380776\n",
       "smoothness_mean              0.096308\n",
       "compactness_mean             0.104091\n",
       "concavity_mean               0.087907\n",
       "concave points_mean          0.048513\n",
       "symmetry_mean                0.181147\n",
       "fractal_dimension_mean       0.062823\n",
       "radius_se                    0.397042\n",
       "texture_se                   1.216239\n",
       "perimeter_se                 2.804511\n",
       "area_se                     38.596116\n",
       "smoothness_se                0.007029\n",
       "compactness_se               0.025424\n",
       "concavity_se                 0.031751\n",
       "concave points_se            0.011767\n",
       "symmetry_se                  0.020500\n",
       "fractal_dimension_se         0.003792\n",
       "radius_worst                16.213437\n",
       "texture_worst               25.679894\n",
       "perimeter_worst            106.864074\n",
       "area_worst                 871.779189\n",
       "smoothness_worst             0.132395\n",
       "compactness_worst            0.254144\n",
       "concavity_worst              0.271379\n",
       "concave points_worst         0.114266\n",
       "symmetry_worst               0.290342\n",
       "fractal_dimension_worst      0.084013\n",
       "dtype: float64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finding feature which should be rescaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_max = X.max()\n",
    "features_to_rescale = X_max[np.abs(X.max()) > 2].index.tolist()\n",
    "X[features_to_rescale] = StandardScaler().fit_transform(X[features_to_rescale])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans(object):\n",
    "    def __init__(self, K, metric='L2', max_iter=200, eps=1e-4, center_init='random'):\n",
    "        self.K = K\n",
    "        self.max_iter = max_iter\n",
    "        self.eps = eps\n",
    "        self.centroids = np.array([])\n",
    "        self.metric = metric.lower()\n",
    "        self.center_init = center_init.lower()\n",
    "\n",
    "        \"\"\"\n",
    "        if metric is 'L2' let self.dist be a function that computes euclidian distance between x and y vectors,\n",
    "        if metric is 'L1' let self.dist be a function that computes manhattan distance between x and y vectors,\n",
    "        otherwise raise not implemented error\n",
    "        \"\"\"\n",
    "        if self.metric == 'l2':\n",
    "            self.dist = self.l2_dist\n",
    "        elif self.metric == 'l1':\n",
    "            self.dist = self.l1_dist\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'KMeans object: metric={self.metric}, center_init={self.center_init}, K={self.K}, max_iter={self.max_iter}, eps={self.eps}'\n",
    "\n",
    "    def distortion(self, X, r):\n",
    "        \"\"\"\n",
    "        param X: numpy array of shape (M,N)\n",
    "        param r: numpy array of shape (M), shows to which cluster each row of X belongs\n",
    "        return: distortion value of the dataset\n",
    "        \"\"\"\n",
    "        sum_ = 0\n",
    "        for k in range(self.K):\n",
    "            mask = r[:, k] == 1\n",
    "            X_k = X[mask]\n",
    "            sum_ += np.sum(self.dist(X_k, self.centroids[k]))\n",
    "        print('distortion: ', sum_)\n",
    "        return sum_\n",
    "\n",
    "    def init_centroids(self, X):\n",
    "        \"\"\"\n",
    "        :param X: numpy array of shape (M,N)\n",
    "        \"\"\"\n",
    "        \"\"\" \n",
    "        If centers_init is 'random' initialize self.centroids with random K items from X,\n",
    "        if it is 'kmeans++' initialize centroids according to the algorithm in \n",
    "        http://ilpubs.stanford.edu:8090/778/1/2006-13.pdf page 3,\n",
    "        otherwise raise not implemented error .\n",
    "        \"\"\"\n",
    "        if self.center_init.lower() == 'random':\n",
    "            self.centroids = self.random_init(X)\n",
    "        elif self.center_init.lower() == 'kmeans++':\n",
    "            self.centroids = self.kmeans_plus_plus_init(X)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        :param X: numpy array of shape (M,N)\n",
    "        \"\"\"\n",
    "        \"\"\" \n",
    "        1. Initialize cluster centers using self.init_centroids method\n",
    "        2. Implement KMeans algorithm and  terminate it when either self.max_iter iterations are performed,\n",
    "        or the biggest change in cluster centers is smaller than selfk means formula.eps\n",
    "\n",
    "        The final cluster centers should be saved in self.centroids\n",
    "        \"\"\"\n",
    "        step = 0\n",
    "        self.init_centroids(X)\n",
    "        r = self.recalculate_r(X)\n",
    "        curr_distortion = self.distortion(X, r)\n",
    "\n",
    "        while step <= self.max_iter:\n",
    "            r = self.recalculate_r(X)\n",
    "            self.recalculate_centroids(X, r)\n",
    "\n",
    "            prev_distortion = curr_distortion\n",
    "            curr_distortion = self.distortion(X, r)\n",
    "            if np.abs(prev_distortion - curr_distortion) <= self.eps:\n",
    "                print(f'Required precision achieved on {step}-th step')\n",
    "                break\n",
    "\n",
    "            step += 1\n",
    "        else:\n",
    "            print('Maximum iterations run out!')\n",
    "\n",
    "    def recalculate_centroids(self, X, r):\n",
    "        for k in range(self.K):\n",
    "            mask = r[:, k] == 1\n",
    "            numerator = X[mask].sum(axis=0)\n",
    "            denominator = r[:, k].sum()\n",
    "            self.centroids[k] = numerator / denominator\n",
    "\n",
    "    def recalculate_r(self, X):\n",
    "        num_rows, num_columns = X.shape\n",
    "        r = np.zeros(shape=(num_rows, self.K), dtype=int)\n",
    "        indices = self.find_closest_distances(X, self.centroids)[:, 1].astype('int')\n",
    "        for i in range(len(indices)):\n",
    "            r[i, indices[i]] = 1\n",
    "        return r\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        :param X: numpy array of shape (M,N)\n",
    "        :return: numpy array of shape (M,)\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        using  self.centroids predict to which cluster each datapoint of X belongs, values in returned array\n",
    "        are integers(id of the cluster). \n",
    "        \"\"\"\n",
    "        return self.find_closest_distances(X, self.centroids)[:, 1].astype('int')\n",
    "\n",
    "    def random_init(self, X):\n",
    "        # for each feature define its boundaries, i.e. minimum and maximum values\n",
    "        min_boundary = X.min(axis=0)\n",
    "        max_boundary = X.max(axis=0)\n",
    "\n",
    "        # return K random vectors of size X.shape[1]\n",
    "        centroids = np.random.uniform(low=min_boundary, high=max_boundary, size=(self.K, min_boundary.shape[0]))\n",
    "        return centroids\n",
    "\n",
    "    def kmeans_plus_plus_init(self, X):\n",
    "        num_rows, num_columns = X.shape\n",
    "        # step 1a. Take one center c1, chosen uniformly at random from X\n",
    "        centroids = np.array(X[np.random.randint(num_rows)])\n",
    "        centroids = centroids.reshape(-1, len(centroids))\n",
    "\n",
    "        # step2a.  Take a new center c[i], choosing x ∈ X with probability D(x)**2/sum(D(x)**2)\n",
    "        for i in range(self.K - 1):\n",
    "            distances = self.find_closest_distances(X, centroids)[:, 0]\n",
    "            probabilities = self.get_probabilities(distances)\n",
    "            max_proba_index = np.argwhere(probabilities == np.amax(probabilities))[0][0]\n",
    "\n",
    "            # reshape 1d to 2d for appending\n",
    "            new_centroid = X[max_proba_index].reshape(-1, len(X[max_proba_index]))\n",
    "            centroids = np.append(centroids, new_centroid, axis=0)\n",
    "        return centroids\n",
    "\n",
    "    def get_probabilities(self, distances):\n",
    "        squared = distances ** 2\n",
    "        sum_ = np.sum(squared)\n",
    "        return squared / sum_\n",
    "\n",
    "    def find_closest_distances(self, X, centroids):\n",
    "        '''\n",
    "        :param X:\n",
    "        :param centroids:\n",
    "        :return: an array where i-th row is associated with i-th row in X\n",
    "                 and has two elements: closest distance to centroid and index of that centroid\n",
    "        '''\n",
    "\n",
    "        num_rows = X.shape[0]\n",
    "        closest_distances = np.zeros(shape=(num_rows, 2))\n",
    "\n",
    "        for i in range(num_rows):\n",
    "            # array of distances between current point and centroids\n",
    "            distances = self.dist(centroids, X[i])\n",
    "            # index of min element in distances assigned to indices array\n",
    "            min_distance = np.amin(distances)\n",
    "            closest_distances[i] = min_distance, np.argwhere(distances == min_distance)\n",
    "        return closest_distances\n",
    "\n",
    "    def l2_dist(self, X, Y):\n",
    "        return np.sqrt(np.sum((X - Y) ** 2, axis=1))\n",
    "\n",
    "    def l1_dist(self, X, Y):\n",
    "        return np.sum(np.abs(X - Y), axis=1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster the dataset with kmeans, model and predict malignancy of tumors in the test set entries\n",
    "## 1. Perform clustering using the following hyperparameter pairs\n",
    "1. metric='L1', center_init='random'\n",
    "2. metric='L1', center_init='kmeans++'\n",
    "3. metric='L2', center_init='random'\n",
    "4. metric='L2', center_init='kmeans++'\n",
    "\n",
    "## 2. Predict malignancy of tumors in the test set entries using all 4 models trained above, compare their performances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = KMeans(K=2, metric='L1', center_init='random')\n",
    "clf2 = KMeans(K=2, metric='L1', center_init='kmeans++')\n",
    "clf3 = KMeans(K=2, metric='L2', center_init='random')\n",
    "clf4 = KMeans(K=2, metric='L2', center_init='kmeans++')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans object: metric=l1, center_init=random, K=2, max_iter=200, eps=0.0001\n",
      "distortion:  12979.37126814362\n",
      "distortion:  5071.958889077876\n",
      "distortion:  4114.00841895424\n",
      "distortion:  3718.8185222248403\n",
      "distortion:  3644.6172601562207\n",
      "distortion:  3615.0103298062722\n",
      "distortion:  3600.471961444086\n",
      "distortion:  3596.1051262594005\n",
      "distortion:  3596.1051262594005\n",
      "Required precision achieved on 7-th step\n",
      "accuracy_score:  0.8589065255731922\n"
     ]
    }
   ],
   "source": [
    "print(clf1)\n",
    "clf1.fit(X.values)\n",
    "clusters = clf1.predict(X.values)\n",
    "\n",
    "labels = np.zeros_like(clusters)\n",
    "for i in range(2):\n",
    "    mask = (clusters == i)\n",
    "    labels[mask] = mode(y[mask])[0]\n",
    "print(f'accuracy_score: ', accuracy_score(y, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans object: metric=l1, center_init=kmeans++, K=2, max_iter=200, eps=0.0001\n",
      "distortion:  6034.62366609218\n",
      "distortion:  4634.597479175499\n",
      "distortion:  3932.464147812023\n",
      "distortion:  3693.5453965169745\n",
      "distortion:  3633.6072439600593\n",
      "distortion:  3612.413435569223\n",
      "distortion:  3598.13723774101\n",
      "distortion:  3596.1051262594005\n",
      "distortion:  3596.1051262594005\n",
      "Required precision achieved on 7-th step\n",
      "accuracy score:  0.8589065255731922\n"
     ]
    }
   ],
   "source": [
    "print(clf2)\n",
    "clf2.fit(X.values)\n",
    "clusters = clf2.predict(X.values)\n",
    "\n",
    "labels = np.zeros_like(clusters)\n",
    "for i in range(2):\n",
    "    mask = (clusters == i)\n",
    "    labels[mask] = mode(y[mask])[0]\n",
    "print(f'accuracy score: ', accuracy_score(y, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans object: metric=l2, center_init=random, K=2, max_iter=200, eps=0.0001\n",
      "distortion:  5578.647412985363\n",
      "distortion:  1612.8061125461174\n",
      "distortion:  1512.2280524348457\n",
      "distortion:  1376.4038364461246\n",
      "distortion:  1266.0673805249844\n",
      "distortion:  1216.8786817007417\n",
      "distortion:  1205.6770393131221\n",
      "distortion:  1204.1622571071634\n",
      "distortion:  1204.7129275867403\n",
      "distortion:  1205.0710085939786\n",
      "distortion:  1205.6852991491523\n",
      "distortion:  1205.6852991491523\n",
      "Required precision achieved on 10-th step\n",
      "accuracy score:  0.8659611992945326\n"
     ]
    }
   ],
   "source": [
    "print(clf3)\n",
    "clf3.fit(X.values)\n",
    "clusters = clf3.predict(X.values)\n",
    "\n",
    "labels = np.zeros_like(clusters)\n",
    "for i in range(2):\n",
    "    mask = (clusters == i)\n",
    "    labels[mask] = mode(y[mask])[0]\n",
    "print(f'accuracy score: ', accuracy_score(y, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans object: metric=l2, center_init=kmeans++, K=2, max_iter=200, eps=0.0001\n",
      "distortion:  1818.38232508054\n",
      "distortion:  1499.4790851885618\n",
      "distortion:  1301.4349756481806\n",
      "distortion:  1232.4626658569848\n",
      "distortion:  1212.8598854927616\n",
      "distortion:  1209.2607644235163\n",
      "distortion:  1207.112040091141\n",
      "distortion:  1207.112040091141\n",
      "Required precision achieved on 6-th step\n",
      "accuracy score:  0.8624338624338624\n"
     ]
    }
   ],
   "source": [
    "print(clf4)\n",
    "clf4.fit(X.values)\n",
    "clusters = clf4.predict(X.values)\n",
    "\n",
    "labels = np.zeros_like(clusters)\n",
    "for i in range(2):\n",
    "    mask = (clusters == i)\n",
    "    labels[mask] = mode(y[mask])[0]\n",
    "print(f'accuracy score: ', accuracy_score(y, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit your implementation of Logistic Regression on the dataset, predict on test set and compare the results with kmeans approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the coefficients of fitted logistic regression model, drop 2 most unimportant features and train again Logistic regression and Kmeans with best metric, center_init hyperparameters, evaluate and compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the coefficients of fitted initial logistic regression model(using all features), select two most important features and train again Logistic regression and Kmeans with best metric, center_init hyperparameters, evaluate and compare results, make the following plot using the test set:\n",
    "\n",
    "datapoints with cluster centers and decision boundary, color the datapoints according to Kmeans predictions\n",
    "color the datapoints on which predictions of logistic regression and Kmeans disagree with separate color\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare performance of best Kmeans model with the performance of Kmeans in sklearn library, using the same hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
