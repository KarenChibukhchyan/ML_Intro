{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mode\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load and process dataset\n",
    "load breast_cancer.csv, drop columns \"id\" and \"Unnamed: 32\", investigate the dataset, and divide into train and test with 80/20 ratio, map values of \"diagnosis\" from (\"B\",\"M\") to (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = pd.read_csv('breast_cancer.csv')\n",
    "X = original_data.drop(['id', 'Unnamed: 32'], axis=1)\n",
    "target_col = 'diagnosis'\n",
    "X.loc[X[target_col] == 'M', 'diagnosis'] = 1\n",
    "X.loc[X[target_col] == 'B', 'diagnosis'] = 0\n",
    "X[target_col] = X[target_col].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "setting number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "K = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRELATION MATRIX:\n",
      "Correlation between area_mean and target column:  0.7089838365853909\n",
      "Correlation between area_se and target column:  0.5482359402780249\n",
      "Correlation between area_worst and target column:  0.7338250349210516\n",
      "Correlation between compactness_mean and target column:  0.5965336775082529\n",
      "Correlation between compactness_se and target column:  0.2929992442488583\n",
      "Correlation between compactness_worst and target column:  0.5909982378417925\n",
      "Correlation between concave points_mean and target column:  0.7766138400204361\n",
      "Correlation between concave points_se and target column:  0.40804233271650514\n",
      "Correlation between concave points_worst and target column:  0.7935660171412696\n",
      "Correlation between concavity_mean and target column:  0.6963597071719053\n",
      "Correlation between concavity_se and target column:  0.2537297659808306\n",
      "Correlation between concavity_worst and target column:  0.6596102103692344\n",
      "Correlation between fractal_dimension_mean and target column:  -0.012837602698432364\n",
      "Correlation between fractal_dimension_se and target column:  0.0779724173902561\n",
      "Correlation between fractal_dimension_worst and target column:  0.3238721887208239\n",
      "Correlation between perimeter_mean and target column:  0.742635529725833\n",
      "Correlation between perimeter_se and target column:  0.5561407034314833\n",
      "Correlation between perimeter_worst and target column:  0.782914137173759\n",
      "Correlation between radius_mean and target column:  0.7300285113754569\n",
      "Correlation between radius_se and target column:  0.5671338208247176\n",
      "Correlation between radius_worst and target column:  0.7764537785950388\n",
      "Correlation between smoothness_mean and target column:  0.3585599650859322\n",
      "Correlation between smoothness_se and target column:  -0.06701601057948744\n",
      "Correlation between smoothness_worst and target column:  0.4214648610664031\n",
      "Correlation between symmetry_mean and target column:  0.3304985542625467\n",
      "Correlation between symmetry_se and target column:  -0.006521755870647959\n",
      "Correlation between symmetry_worst and target column:  0.41629431104861897\n",
      "Correlation between texture_mean and target column:  0.4151852998452046\n",
      "Correlation between texture_se and target column:  -0.008303332973877434\n",
      "Correlation between texture_worst and target column:  0.4569028213967982\n"
     ]
    }
   ],
   "source": [
    "print('CORRELATION MATRIX:')\n",
    "for feature in X.columns.difference([target_col]):\n",
    "    print(f'Correlation between {feature} and target column: ', X[[feature, target_col]].corr().iloc[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X[target_col]\n",
    "X.drop(target_col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of malignant diagnosis:  357\n",
      "Number of benign diagnosis:  212\n"
     ]
    }
   ],
   "source": [
    "print('Number of malignant diagnosis: ', y.value_counts().loc[0])\n",
    "print('Number of benign diagnosis: ', y.value_counts().loc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>radius_se</th>\n",
       "      <th>texture_se</th>\n",
       "      <th>perimeter_se</th>\n",
       "      <th>area_se</th>\n",
       "      <th>smoothness_se</th>\n",
       "      <th>compactness_se</th>\n",
       "      <th>concavity_se</th>\n",
       "      <th>concave points_se</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>0.405172</td>\n",
       "      <td>1.216853</td>\n",
       "      <td>2.866059</td>\n",
       "      <td>40.337079</td>\n",
       "      <td>0.007041</td>\n",
       "      <td>0.025478</td>\n",
       "      <td>0.031894</td>\n",
       "      <td>0.011796</td>\n",
       "      <td>0.020542</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.277313</td>\n",
       "      <td>0.551648</td>\n",
       "      <td>2.021855</td>\n",
       "      <td>45.491006</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.017908</td>\n",
       "      <td>0.030186</td>\n",
       "      <td>0.006170</td>\n",
       "      <td>0.008266</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>0.111500</td>\n",
       "      <td>0.360200</td>\n",
       "      <td>0.757000</td>\n",
       "      <td>6.802000</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007882</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>0.232400</td>\n",
       "      <td>0.833900</td>\n",
       "      <td>1.606000</td>\n",
       "      <td>17.850000</td>\n",
       "      <td>0.005169</td>\n",
       "      <td>0.013080</td>\n",
       "      <td>0.015090</td>\n",
       "      <td>0.007638</td>\n",
       "      <td>0.015160</td>\n",
       "      <td>0.002248</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.324200</td>\n",
       "      <td>1.108000</td>\n",
       "      <td>2.287000</td>\n",
       "      <td>24.530000</td>\n",
       "      <td>0.006380</td>\n",
       "      <td>0.020450</td>\n",
       "      <td>0.025890</td>\n",
       "      <td>0.010930</td>\n",
       "      <td>0.018730</td>\n",
       "      <td>0.003187</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>0.478900</td>\n",
       "      <td>1.474000</td>\n",
       "      <td>3.357000</td>\n",
       "      <td>45.190000</td>\n",
       "      <td>0.008146</td>\n",
       "      <td>0.032450</td>\n",
       "      <td>0.042050</td>\n",
       "      <td>0.014710</td>\n",
       "      <td>0.023480</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>2.873000</td>\n",
       "      <td>4.885000</td>\n",
       "      <td>21.980000</td>\n",
       "      <td>542.200000</td>\n",
       "      <td>0.031130</td>\n",
       "      <td>0.135400</td>\n",
       "      <td>0.396000</td>\n",
       "      <td>0.052790</td>\n",
       "      <td>0.078950</td>\n",
       "      <td>0.029840</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       radius_mean  texture_mean  perimeter_mean    area_mean  smoothness_mean  compactness_mean  concavity_mean  concave points_mean  symmetry_mean  fractal_dimension_mean   radius_se  texture_se  perimeter_se     area_se  smoothness_se  compactness_se  concavity_se  concave points_se  symmetry_se  fractal_dimension_se  radius_worst  texture_worst  perimeter_worst   area_worst  smoothness_worst  compactness_worst  concavity_worst  concave points_worst  symmetry_worst  fractal_dimension_worst\n",
       "count   569.000000    569.000000      569.000000   569.000000       569.000000        569.000000      569.000000           569.000000     569.000000              569.000000  569.000000  569.000000    569.000000  569.000000     569.000000      569.000000    569.000000         569.000000   569.000000            569.000000    569.000000     569.000000       569.000000   569.000000        569.000000         569.000000       569.000000            569.000000      569.000000               569.000000\n",
       "mean     14.127292     19.289649       91.969033   654.889104         0.096360          0.104341        0.088799             0.048919       0.181162                0.062798    0.405172    1.216853      2.866059   40.337079       0.007041        0.025478      0.031894           0.011796     0.020542              0.003795     16.269190      25.677223       107.261213   880.583128          0.132369           0.254265         0.272188              0.114606        0.290076                 0.083946\n",
       "std       3.524049      4.301036       24.298981   351.914129         0.014064          0.052813        0.079720             0.038803       0.027414                0.007060    0.277313    0.551648      2.021855   45.491006       0.003003        0.017908      0.030186           0.006170     0.008266              0.002646      4.833242       6.146258        33.602542   569.356993          0.022832           0.157336         0.208624              0.065732        0.061867                 0.018061\n",
       "min       6.981000      9.710000       43.790000   143.500000         0.052630          0.019380        0.000000             0.000000       0.106000                0.049960    0.111500    0.360200      0.757000    6.802000       0.001713        0.002252      0.000000           0.000000     0.007882              0.000895      7.930000      12.020000        50.410000   185.200000          0.071170           0.027290         0.000000              0.000000        0.156500                 0.055040\n",
       "25%      11.700000     16.170000       75.170000   420.300000         0.086370          0.064920        0.029560             0.020310       0.161900                0.057700    0.232400    0.833900      1.606000   17.850000       0.005169        0.013080      0.015090           0.007638     0.015160              0.002248     13.010000      21.080000        84.110000   515.300000          0.116600           0.147200         0.114500              0.064930        0.250400                 0.071460\n",
       "50%      13.370000     18.840000       86.240000   551.100000         0.095870          0.092630        0.061540             0.033500       0.179200                0.061540    0.324200    1.108000      2.287000   24.530000       0.006380        0.020450      0.025890           0.010930     0.018730              0.003187     14.970000      25.410000        97.660000   686.500000          0.131300           0.211900         0.226700              0.099930        0.282200                 0.080040\n",
       "75%      15.780000     21.800000      104.100000   782.700000         0.105300          0.130400        0.130700             0.074000       0.195700                0.066120    0.478900    1.474000      3.357000   45.190000       0.008146        0.032450      0.042050           0.014710     0.023480              0.004558     18.790000      29.720000       125.400000  1084.000000          0.146000           0.339100         0.382900              0.161400        0.317900                 0.092080\n",
       "max      28.110000     39.280000      188.500000  2501.000000         0.163400          0.345400        0.426800             0.201200       0.304000                0.097440    2.873000    4.885000     21.980000  542.200000       0.031130        0.135400      0.396000           0.052790     0.078950              0.029840     36.040000      49.540000       251.200000  4254.000000          0.222600           1.058000         1.252000              0.291000        0.663800                 0.207500"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "radius_mean                 14.127292\n",
       "texture_mean                19.289649\n",
       "perimeter_mean              91.969033\n",
       "area_mean                  654.889104\n",
       "smoothness_mean              0.096360\n",
       "compactness_mean             0.104341\n",
       "concavity_mean               0.088799\n",
       "concave points_mean          0.048919\n",
       "symmetry_mean                0.181162\n",
       "fractal_dimension_mean       0.062798\n",
       "radius_se                    0.405172\n",
       "texture_se                   1.216853\n",
       "perimeter_se                 2.866059\n",
       "area_se                     40.337079\n",
       "smoothness_se                0.007041\n",
       "compactness_se               0.025478\n",
       "concavity_se                 0.031894\n",
       "concave points_se            0.011796\n",
       "symmetry_se                  0.020542\n",
       "fractal_dimension_se         0.003795\n",
       "radius_worst                16.269190\n",
       "texture_worst               25.677223\n",
       "perimeter_worst            107.261213\n",
       "area_worst                 880.583128\n",
       "smoothness_worst             0.132369\n",
       "compactness_worst            0.254265\n",
       "concavity_worst              0.272188\n",
       "concave points_worst         0.114606\n",
       "symmetry_worst               0.290076\n",
       "fractal_dimension_worst      0.083946\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finding feature which should be rescaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_max = X.max()\n",
    "features_to_rescale = X_max[np.abs(X.max()) > 2].index.tolist()\n",
    "X[features_to_rescale] = StandardScaler().fit_transform(X[features_to_rescale])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans(object):\n",
    "    def __init__(self, K, metric='L2', max_iter=200, eps=1e-4, center_init='random'):\n",
    "        self.K = K\n",
    "        self.max_iter = max_iter\n",
    "        self.eps = eps\n",
    "        self.centroids = np.array([])\n",
    "        self.metric = metric.lower()\n",
    "        self.center_init = center_init.lower()\n",
    "\n",
    "        \"\"\"\n",
    "        if metric is 'L2' let self.dist be a function that computes euclidian distance between x and y vectors,\n",
    "        if metric is 'L1' let self.dist be a function that computes manhattan distance between x and y vectors,\n",
    "        otherwise raise not implemented error\n",
    "        \"\"\"\n",
    "        if self.metric == 'l2':\n",
    "            self.dist = self.l2_dist\n",
    "        elif self.metric == 'l1':\n",
    "            self.dist = self.l1_dist\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'KMeans object: metric={self.metric}, center_init={self.center_init}, K={self.K}, max_iter={self.max_iter}, eps={self.eps}'\n",
    "\n",
    "    def distortion(self, X, r):\n",
    "        \"\"\"\n",
    "        param X: numpy array of shape (M,N)\n",
    "        param r: numpy array of shape (M), shows to which cluster each row of X belongs\n",
    "        return: distortion value of the dataset\n",
    "        \"\"\"\n",
    "        sum_ = 0\n",
    "        for k in range(self.K):\n",
    "            mask = r[:, k] == 1\n",
    "            X_k = X[mask]\n",
    "            sum_ += np.sum(self.dist(X_k, self.centroids[k]))\n",
    "        print('distortion: ', sum_)\n",
    "        return sum_\n",
    "\n",
    "    def init_centroids(self, X):\n",
    "        \"\"\"\n",
    "        :param X: numpy array of shape (M,N)\n",
    "        \"\"\"\n",
    "        \"\"\" \n",
    "        If centers_init is 'random' initialize self.centroids with random K items from X,\n",
    "        if it is 'kmeans++' initialize centroids according to the algorithm in \n",
    "        http://ilpubs.stanford.edu:8090/778/1/2006-13.pdf page 3,\n",
    "        otherwise raise not implemented error .\n",
    "        \"\"\"\n",
    "        if self.center_init.lower() == 'random':\n",
    "            self.centroids = self.random_init(X)\n",
    "        elif self.center_init.lower() == 'kmeans++':\n",
    "            self.centroids = self.kmeans_plus_plus_init(X)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        :param X: numpy array of shape (M,N)\n",
    "        \"\"\"\n",
    "        \"\"\" \n",
    "        1. Initialize cluster centers using self.init_centroids method\n",
    "        2. Implement KMeans algorithm and  terminate it when either self.max_iter iterations are performed,\n",
    "        or the biggest change in cluster centers is smaller than selfk means formula.eps\n",
    "\n",
    "        The final cluster centers should be saved in self.centroids\n",
    "        \"\"\"\n",
    "        step = 0\n",
    "        self.init_centroids(X)\n",
    "        r = self.recalculate_r(X)\n",
    "        curr_distortion = self.distortion(X, r)\n",
    "\n",
    "        while step <= self.max_iter:\n",
    "            r = self.recalculate_r(X)\n",
    "            self.recalculate_centroids(X, r)\n",
    "\n",
    "            prev_distortion = curr_distortion\n",
    "            curr_distortion = self.distortion(X, r)\n",
    "            if np.abs(prev_distortion - curr_distortion) <= self.eps:\n",
    "                print(f'Required precision achieved on {step}-th step')\n",
    "                break\n",
    "\n",
    "            step += 1\n",
    "        else:\n",
    "            print('Maximum iterations run out!')\n",
    "\n",
    "    def recalculate_centroids(self, X, r):\n",
    "        for k in range(self.K):\n",
    "            mask = r[:, k] == 1\n",
    "            numerator = X[mask].sum(axis=0)\n",
    "            denominator = r[:, k].sum()\n",
    "            self.centroids[k] = numerator / denominator\n",
    "\n",
    "    def recalculate_r(self, X):\n",
    "        num_rows, num_columns = X.shape\n",
    "        r = np.zeros(shape=(num_rows, self.K), dtype=int)\n",
    "        indices = self.find_closest_distances(X, self.centroids)[:, 1].astype('int')\n",
    "        for i in range(len(indices)):\n",
    "            r[i, indices[i]] = 1\n",
    "        return r\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        :param X: numpy array of shape (M,N)\n",
    "        :return: numpy array of shape (M,)\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        using  self.centroids predict to which cluster each datapoint of X belongs, values in returned array\n",
    "        are integers(id of the cluster). \n",
    "        \"\"\"\n",
    "        return self.find_closest_distances(X, self.centroids)[:, 1].astype('int')\n",
    "\n",
    "    def random_init(self, X):\n",
    "        # for each feature define its boundaries, i.e. minimum and maximum values\n",
    "        min_boundary = X.min(axis=0)\n",
    "        max_boundary = X.max(axis=0)\n",
    "\n",
    "        # return K random vectors of size X.shape[1]\n",
    "        centroids = np.random.uniform(low=min_boundary, high=max_boundary, size=(self.K, min_boundary.shape[0]))\n",
    "        return centroids\n",
    "\n",
    "    def kmeans_plus_plus_init(self, X):\n",
    "        num_rows, num_columns = X.shape\n",
    "        # step 1a. Take one center c1, chosen uniformly at random from X\n",
    "        centroids = np.array(X[np.random.randint(num_rows)])\n",
    "        centroids = centroids.reshape(-1, len(centroids))\n",
    "\n",
    "        # step2a.  Take a new center c[i], choosing x ∈ X with probability D(x)**2/sum(D(x)**2)\n",
    "        for i in range(self.K - 1):\n",
    "            distances = self.find_closest_distances(X, centroids)[:, 0]\n",
    "            probabilities = self.get_probabilities(distances)\n",
    "            max_proba_index = np.argwhere(probabilities == np.amax(probabilities))[0][0]\n",
    "\n",
    "            # reshape 1d to 2d for appending\n",
    "            new_centroid = X[max_proba_index].reshape(-1, len(X[max_proba_index]))\n",
    "            centroids = np.append(centroids, new_centroid, axis=0)\n",
    "        return centroids\n",
    "\n",
    "    def get_probabilities(self, distances):\n",
    "        squared = distances ** 2\n",
    "        sum_ = np.sum(squared)\n",
    "        return squared / sum_\n",
    "\n",
    "    def find_closest_distances(self, X, centroids):\n",
    "        '''\n",
    "        :param X:\n",
    "        :param centroids:\n",
    "        :return: an array where i-th row is associated with i-th row in X\n",
    "                 and has two elements: closest distance to centroid and index of that centroid\n",
    "        '''\n",
    "\n",
    "        num_rows = X.shape[0]\n",
    "        closest_distances = np.zeros(shape=(num_rows, 2))\n",
    "\n",
    "        for i in range(num_rows):\n",
    "            # array of distances between current point and centroids\n",
    "            distances = self.dist(centroids, X[i])\n",
    "            # index of min element in distances assigned to indices array\n",
    "            min_distance = np.amin(distances)\n",
    "            closest_distances[i] = min_distance, np.argwhere(distances == min_distance)\n",
    "        return closest_distances\n",
    "\n",
    "    def l2_dist(self, X, Y):\n",
    "        return np.sqrt(np.sum((X - Y) ** 2, axis=1))\n",
    "\n",
    "    def l1_dist(self, X, Y):\n",
    "        return np.sum(np.abs(X - Y), axis=1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster the dataset with kmeans, model and predict malignancy of tumors in the test set entries\n",
    "## 1. Perform clustering using the following hyperparameter pairs\n",
    "1. metric='L1', center_init='random'\n",
    "2. metric='L1', center_init='kmeans++'\n",
    "3. metric='L2', center_init='random'\n",
    "4. metric='L2', center_init='kmeans++'\n",
    "\n",
    "## 2. Predict malignancy of tumors in the test set entries using all 4 models trained above, compare their performances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = KMeans(K=2, metric='L1', center_init='random')\n",
    "clf2 = KMeans(K=2, metric='L1', center_init='kmeans++')\n",
    "clf3 = KMeans(K=2, metric='L2', center_init='random')\n",
    "clf4 = KMeans(K=2, metric='L2', center_init='kmeans++')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans object: metric=l1, center_init=random, K=2, max_iter=200, eps=0.0001\n",
      "distortion:  20669.671994324886\n",
      "distortion:  4275.327582468298\n",
      "distortion:  3738.9665274646704\n",
      "distortion:  3740.4167892420433\n",
      "distortion:  3742.6761338821498\n",
      "distortion:  3744.805060625072\n",
      "distortion:  3744.805060625072\n",
      "Required precision achieved on 5-th step\n",
      "accuracy_score:  0.8558875219683656\n"
     ]
    }
   ],
   "source": [
    "print(clf1)\n",
    "clf1.fit(X.values)\n",
    "clusters = clf1.predict(X.values)\n",
    "\n",
    "labels = np.zeros_like(clusters)\n",
    "for i in range(2):\n",
    "    mask = (clusters == i)\n",
    "    labels[mask] = mode(y[mask])[0]\n",
    "\n",
    "print(f'accuracy_score: ', accuracy_score(y, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans object: metric=l1, center_init=kmeans++, K=2, max_iter=200, eps=0.0001\n",
      "distortion:  6129.235803024898\n",
      "distortion:  5245.3026550558825\n",
      "distortion:  4954.970007473213\n",
      "distortion:  4540.023297391273\n",
      "distortion:  4002.6059842313502\n",
      "distortion:  3831.7524738843526\n",
      "distortion:  3791.218926165193\n",
      "distortion:  3769.4416050589784\n",
      "distortion:  3760.452902863036\n",
      "distortion:  3752.665021343435\n",
      "distortion:  3747.3031014839244\n",
      "distortion:  3744.805060625072\n",
      "distortion:  3744.805060625072\n",
      "Required precision achieved on 11-th step\n",
      "accuracy score:  0.8558875219683656\n"
     ]
    }
   ],
   "source": [
    "print(clf2)\n",
    "clf2.fit(X.values)\n",
    "clusters = clf2.predict(X.values)\n",
    "\n",
    "labels = np.zeros_like(clusters)\n",
    "for i in range(2):\n",
    "    mask = (clusters == i)\n",
    "    labels[mask] = mode(y[mask])[0]\n",
    "print(f'accuracy score: ', accuracy_score(y, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans object: metric=l2, center_init=random, K=2, max_iter=200, eps=0.0001\n",
      "distortion:  6351.107274480177\n",
      "distortion:  1446.6337259364627\n",
      "distortion:  1246.5453451155147\n",
      "distortion:  1242.4712903325444\n",
      "distortion:  1240.6426333605189\n",
      "distortion:  1240.6426333605189\n",
      "Required precision achieved on 4-th step\n",
      "accuracy score:  0.8576449912126538\n"
     ]
    }
   ],
   "source": [
    "print(clf3)\n",
    "clf3.fit(X.values)\n",
    "clusters = clf3.predict(X.values)\n",
    "\n",
    "labels = np.zeros_like(clusters)\n",
    "for i in range(2):\n",
    "    mask = (clusters == i)\n",
    "    labels[mask] = mode(y[mask])[0]\n",
    "print(f'accuracy score: ', accuracy_score(y, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans object: metric=l2, center_init=kmeans++, K=2, max_iter=200, eps=0.0001\n",
      "distortion:  1789.1356696247522\n",
      "distortion:  1643.3020772902382\n",
      "distortion:  1614.291967968212\n",
      "distortion:  1519.7004715046983\n",
      "distortion:  1376.346206911612\n",
      "distortion:  1272.6541912846237\n",
      "distortion:  1251.2569701298153\n",
      "distortion:  1243.282433176807\n",
      "distortion:  1240.6426333605189\n",
      "distortion:  1240.6426333605189\n",
      "Required precision achieved on 8-th step\n",
      "accuracy score:  0.8576449912126538\n"
     ]
    }
   ],
   "source": [
    "print(clf4)\n",
    "clf4.fit(X.values)\n",
    "clusters = clf4.predict(X.values)\n",
    "\n",
    "labels = np.zeros_like(clusters)\n",
    "for i in range(2):\n",
    "    mask = (clusters == i)\n",
    "    labels[mask] = mode(y[mask])[0]\n",
    "print(f'accuracy score: ', accuracy_score(y, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit your implementation of Logistic Regression on the dataset, predict on test set and compare the results with kmeans approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the coefficients of fitted logistic regression model, drop 2 most unimportant features and train again Logistic regression and Kmeans with best metric, center_init hyperparameters, evaluate and compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the coefficients of fitted initial logistic regression model(using all features), select two most important features and train again Logistic regression and Kmeans with best metric, center_init hyperparameters, evaluate and compare results, make the following plot using the test set:\n",
    "\n",
    "datapoints with cluster centers and decision boundary, color the datapoints according to Kmeans predictions\n",
    "color the datapoints on which predictions of logistic regression and Kmeans disagree with separate color\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare performance of best Kmeans model with the performance of Kmeans in sklearn library, using the same hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
